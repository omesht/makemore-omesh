{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UhkfBaMvHgzA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/omesht/makemore-omesh/refs/heads/master/names.txt'\n",
        "words = requests.get(url).text.splitlines()\n",
        "#words = open('names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-ptf2v3KHgzE"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AkXR0a84HgzF"
      },
      "outputs": [],
      "source": [
        "N = torch.zeros((27, 27, 27), dtype=torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iq1MP_0DHgzF"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2RPHCMylHgzF"
      },
      "outputs": [],
      "source": [
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    N[ix1, ix2, ix3] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow((27*27,27), cmap='Blues')\n",
        "for i in range(27):\n",
        "    for j in range(27):\n",
        "      for k in range(27):\n",
        "        chstr = itos[i] + itos[j] + itos[k]\n",
        "        plt.text(k, ixj, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "        plt.text(k, ixk, N[i, j,k].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "0LHlfrbBZuPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFw5m0RgHgzG",
        "outputId": "aec96df8-2ff5-49b0-e7b3-6d55c41fedd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
              "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
              "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "p = N[0,0].float()+1\n",
        "p = p / p.sum()\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.zeros((2, 2, 2), dtype=torch.int32)\n",
        "A[0,0,0]=1\n",
        "A[0,0,1]=2\n",
        "A[0,1,0]=3\n",
        "A[0,1,1]=4\n",
        "A[1,0,0]=5\n",
        "A[1,0,1]=6\n",
        "A[1,1,0]=7\n",
        "A[1,1,1]=8\n",
        "\n",
        "K = A.float()\n",
        "K.sum(2, keepdims=True)\n",
        "#K = K / K.sum(1)\n",
        "#K.sum(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPx8hmyV_ouA",
        "outputId": "fb59fb1e-9286-4a53-e788-68f156a4d3df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 3.],\n",
              "         [ 7.]],\n",
              "\n",
              "        [[11.],\n",
              "         [15.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GRPDPf54HgzH"
      },
      "outputs": [],
      "source": [
        "P = (N+1).float()\n",
        "P /= P.sum(2, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU8xCNBa3JuB",
        "outputId": "a20fdc85-1972-45fc-f6cb-519ec8d5c404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
              "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
              "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FboBobwMHgzH",
        "outputId": "f60d8b09-d756-4566-9c45-abf2f0ef13ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "ilyasid.\n",
            "prelay.\n",
            "ocin.\n",
            "fairritoper.\n",
            "sathen.\n",
            "dannaaryanileniassibduinrwin.\n",
            "lessiyanayla.\n",
            "te.\n",
            "farmumthyfortumj.\n"
          ]
        }
      ],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  iy = 0\n",
        "  iz = 0\n",
        "  while True:\n",
        "    p = P[ix, iy]\n",
        "    iz = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[iz])\n",
        "    if iz == 0:\n",
        "      break\n",
        "    ix = iy\n",
        "    iy = iz\n",
        "\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_hLJj7PHgzH"
      },
      "outputs": [],
      "source": [
        "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
        "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
        "# equivalent to minimizing the negative log likelihood\n",
        "# equivalent to minimizing the average negative log likelihood\n",
        "\n",
        "# log(a*b*c) = log(a) + log(b) + log(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwYCPzugHgzH",
        "outputId": "687527ad-202c-4f6a-bec2-df0a0b0fd29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_likelihood=tensor(-564996.8125, grad_fn=<AddBackward0>)\n",
            "nll=tensor(564996.8125, grad_fn=<NegBackward0>)\n",
            "2.476470470428467\n"
          ]
        }
      ],
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "#for w in [\"andrejq\"]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], ch[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1, ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print(f'{log_likelihood=}')\n",
        "nll = -log_likelihood\n",
        "print(f'{nll=}')\n",
        "print(f'{nll/n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRJ37ToZHgzI",
        "outputId": "a004b2bc-344c-4d53-e89c-42160d35f109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ". e\n",
            "e m\n",
            "m m\n",
            "m a\n",
            "a .\n"
          ]
        }
      ],
      "source": [
        "# create the training set of bigrams (x,y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    print(ch1, ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uz4EaNgHgzI",
        "outputId": "4dbf40c8-02f1-49ea-dd46-97d247fa5a57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1e0MMYeHgzI",
        "outputId": "6de23243-ccf5-485a-cc9b-9ce64dd45b5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "execution_count": 451,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZb2TQr8HgzI",
        "outputId": "5df5c887-54b7-4279-d375-8dad4cc1ffff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 487,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "xenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qizbM6cZHgzI",
        "outputId": "dc407be0-dbd9-4653-f585-3de450ea6385"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "execution_count": 488,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xenc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyofAeVSHgzI",
        "outputId": "bc98a75c-43f2-4f81-cf26-3b87abaf316c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa0dab44fa0>"
            ]
          },
          "execution_count": 489,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(xenc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfHxaSeOHgzI",
        "outputId": "9860c59e-0524-48da-f9e0-fba77f684957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 490,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xenc.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-25bUlVcHgzJ",
        "outputId": "0f0cd606-56c7-48bf-e14a-a334ff7ff9ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.2003, -2.3711, -0.9466,  0.5369, -0.0949, -1.7872, -0.9038,  0.8194,\n",
              "          0.6926,  0.0114, -1.5301,  0.6077, -1.2056,  1.8605, -1.3012, -0.0301,\n",
              "         -2.1611, -0.0538, -0.0133, -0.3629,  0.5254, -0.0080,  1.1602,  1.9851,\n",
              "          0.4976,  0.7351, -0.6373],\n",
              "        [-0.4422,  0.5024,  1.3514, -0.4085, -0.7854, -1.2568, -0.4558,  0.1466,\n",
              "         -0.4460,  1.2748, -0.6367,  0.6403, -0.5617, -0.3060,  1.6771, -1.4814,\n",
              "         -2.7395,  0.3876,  0.3970,  1.5577, -0.1995, -0.1397, -1.3045,  0.4294,\n",
              "          1.2557,  0.8007,  0.5450],\n",
              "        [-0.2680, -0.2640,  0.4591,  0.0338,  0.7478,  1.2757, -0.9842,  0.1799,\n",
              "          0.0824, -0.5646, -0.3657, -0.8358, -1.7654,  0.5008, -1.7455, -0.8160,\n",
              "         -2.2721,  0.9713, -1.0734,  0.3115, -0.2506,  0.0757,  0.9332,  1.6536,\n",
              "          1.2306,  0.1231, -0.2530],\n",
              "        [-0.2680, -0.2640,  0.4591,  0.0338,  0.7478,  1.2757, -0.9842,  0.1799,\n",
              "          0.0824, -0.5646, -0.3657, -0.8358, -1.7654,  0.5008, -1.7455, -0.8160,\n",
              "         -2.2721,  0.9713, -1.0734,  0.3115, -0.2506,  0.0757,  0.9332,  1.6536,\n",
              "          1.2306,  0.1231, -0.2530],\n",
              "        [ 0.1949, -1.1315,  0.9479, -0.6382, -0.4422, -0.6489,  0.6576, -1.9004,\n",
              "          2.0254,  1.2617, -1.7238,  1.2971, -0.6925, -0.3873,  0.7874, -0.8088,\n",
              "          0.5746, -0.5263, -0.5928,  0.1419,  1.0683, -0.1760, -0.3507, -0.5358,\n",
              "          0.1470,  1.5682, -1.0393]])"
            ]
          },
          "execution_count": 493,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W = torch.randn((27, 1))\n",
        "xenc @ W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pruhylJXHgzJ",
        "outputId": "fd0302b1-ba6f-424b-81f8-17c4f567c879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0205, 0.0023, 0.0097, 0.0428, 0.0228, 0.0042, 0.0101, 0.0568, 0.0500,\n",
              "         0.0253, 0.0054, 0.0460, 0.0075, 0.1609, 0.0068, 0.0243, 0.0029, 0.0237,\n",
              "         0.0247, 0.0174, 0.0423, 0.0248, 0.0799, 0.1822, 0.0412, 0.0522, 0.0132],\n",
              "        [0.0154, 0.0397, 0.0928, 0.0160, 0.0110, 0.0068, 0.0152, 0.0278, 0.0154,\n",
              "         0.0860, 0.0127, 0.0456, 0.0137, 0.0177, 0.1286, 0.0055, 0.0016, 0.0354,\n",
              "         0.0357, 0.1141, 0.0197, 0.0209, 0.0065, 0.0369, 0.0844, 0.0535, 0.0414],\n",
              "        [0.0212, 0.0213, 0.0439, 0.0287, 0.0586, 0.0994, 0.0104, 0.0332, 0.0301,\n",
              "         0.0158, 0.0192, 0.0120, 0.0047, 0.0458, 0.0048, 0.0123, 0.0029, 0.0733,\n",
              "         0.0095, 0.0379, 0.0216, 0.0299, 0.0705, 0.1450, 0.0950, 0.0314, 0.0215],\n",
              "        [0.0212, 0.0213, 0.0439, 0.0287, 0.0586, 0.0994, 0.0104, 0.0332, 0.0301,\n",
              "         0.0158, 0.0192, 0.0120, 0.0047, 0.0458, 0.0048, 0.0123, 0.0029, 0.0733,\n",
              "         0.0095, 0.0379, 0.0216, 0.0299, 0.0705, 0.1450, 0.0950, 0.0314, 0.0215],\n",
              "        [0.0289, 0.0077, 0.0613, 0.0126, 0.0153, 0.0124, 0.0459, 0.0036, 0.1801,\n",
              "         0.0839, 0.0042, 0.0869, 0.0119, 0.0161, 0.0522, 0.0106, 0.0422, 0.0140,\n",
              "         0.0131, 0.0274, 0.0692, 0.0199, 0.0167, 0.0139, 0.0275, 0.1140, 0.0084]])"
            ]
          },
          "execution_count": 506,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits = xenc @ W # log-counts\n",
        "counts = logits.exp() # equivalent N\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzTns3kdHgzJ",
        "outputId": "6d08a478-48cd-4883-c59b-80ecc1c60344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0205, 0.0023, 0.0097, 0.0428, 0.0228, 0.0042, 0.0101, 0.0568, 0.0500,\n",
              "        0.0253, 0.0054, 0.0460, 0.0075, 0.1609, 0.0068, 0.0243, 0.0029, 0.0237,\n",
              "        0.0247, 0.0174, 0.0423, 0.0248, 0.0799, 0.1822, 0.0412, 0.0522, 0.0132])"
            ]
          },
          "execution_count": 509,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Q22IacHgzJ",
        "outputId": "f4fa5539-127a-4da0-8546-80afa5a4bf7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([27])"
            ]
          },
          "execution_count": 510,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yVwHjdnHgzJ",
        "outputId": "ce19f826-8c8b-4971-c8f2-a280287d7d52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "execution_count": 507,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs[0].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo3GSpGOHgzO"
      },
      "outputs": [],
      "source": [
        "# (5, 27) @ (27, 27) -> (5, 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovBtVsahHgzO"
      },
      "outputs": [],
      "source": [
        "# SUMMARY ------------------------------>>>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-tj7W_ZHgzO",
        "outputId": "9936ac11-038d-4934-9996-7dd620d69038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "execution_count": 528,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y8bYQU8HgzO",
        "outputId": "fae43981-56da-44af-c6de-b6d16a589795"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "execution_count": 529,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2YMFz9qHgzO"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4ZOEGG9HgzO"
      },
      "outputs": [],
      "source": [
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# btw: the last 2 lines here are together called a 'softmax'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYgEUNnQHgzO",
        "outputId": "e07df22e-c6b6-4b17-f78b-1349de204b50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "execution_count": 559,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhaXRlKTHgzO",
        "outputId": "4e7ee9b6-477a-4a7f-d68e-91565c1a207b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "bigram example 1: .e (indexes 0,5)\n",
            "input to the neural net: 0\n",
            "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
            "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
            "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
            "label (actual next character): 5\n",
            "probability assigned by the net to the the correct character: 0.012286253273487091\n",
            "log likelihood: -4.3992743492126465\n",
            "negative log likelihood: 4.3992743492126465\n",
            "--------\n",
            "bigram example 2: em (indexes 5,13)\n",
            "input to the neural net: 5\n",
            "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
            "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
            "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the the correct character: 0.018050702288746834\n",
            "log likelihood: -4.014570713043213\n",
            "negative log likelihood: 4.014570713043213\n",
            "--------\n",
            "bigram example 3: mm (indexes 13,13)\n",
            "input to the neural net: 13\n",
            "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
            "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
            "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the the correct character: 0.026691533625125885\n",
            "log likelihood: -3.623408794403076\n",
            "negative log likelihood: 3.623408794403076\n",
            "--------\n",
            "bigram example 4: ma (indexes 13,1)\n",
            "input to the neural net: 13\n",
            "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
            "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
            "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
            "label (actual next character): 1\n",
            "probability assigned by the net to the the correct character: 0.07367684692144394\n",
            "log likelihood: -2.6080667972564697\n",
            "negative log likelihood: 2.6080667972564697\n",
            "--------\n",
            "bigram example 5: a. (indexes 1,0)\n",
            "input to the neural net: 1\n",
            "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
            "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
            "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
            "label (actual next character): 0\n",
            "probability assigned by the net to the the correct character: 0.0149775305762887\n",
            "log likelihood: -4.201204299926758\n",
            "negative log likelihood: 4.201204299926758\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('--------')\n",
        "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probabilities from the neural net:', probs[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i, y]\n",
        "  print('probability assigned by the net to the the correct character:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood:', logp.item())\n",
        "  nll = -logp\n",
        "  print('negative log likelihood:', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcCv7uRzHgzO"
      },
      "outputs": [],
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay --------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YNuL7F_HgzP",
        "outputId": "27817aec-b121-4f44-8902-9301ff5f625d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "execution_count": 565,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqfnqhJ1HgzP",
        "outputId": "1ac60d2f-bcbd-4704-f031-676386c297d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "execution_count": 566,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3Bh2AAjHgzP"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qje_HNEpHgzP"
      },
      "outputs": [],
      "source": [
        "# forward pass\n",
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "loss = -probs[torch.arange(5), ys].log().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf1JuXFoHgzP",
        "outputId": "584b4ffd-4204-4575-c7e6-3a21d3afdebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.6891887187957764\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRJ5pO-eHgzP"
      },
      "outputs": [],
      "source": [
        "# backward pass\n",
        "W.grad = None # set to zero the gradient\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOTb9UacHgzP"
      },
      "outputs": [],
      "source": [
        "W.data += -0.1 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrMHPlvhHgzP"
      },
      "outputs": [],
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iOwTXeqHgzP",
        "outputId": "3e54f497-c5e9-412f-edcd-2d99949d8142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ],
      "source": [
        "# create the dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# initialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGeAKlNpHgzP",
        "outputId": "f12e2462-e882-413d-b65a-75c3ab4dca13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.481828451156616\n"
          ]
        }
      ],
      "source": [
        "# gradient descent\n",
        "for k in range(1):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-bj1jhnHgzP",
        "outputId": "a224bcb8-7f49-40cc-ee4b-2fd1afdcca40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mor.\n",
            "axx.\n",
            "minaymoryles.\n",
            "kondlaisah.\n",
            "anchthizarie.\n"
          ]
        }
      ],
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "\n",
        "    # ----------\n",
        "    # BEFORE:\n",
        "    #p = P[ix]\n",
        "    # ----------\n",
        "    # NOW:\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    # ----------\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twafdXfwHgzQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}