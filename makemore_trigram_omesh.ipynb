{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UhkfBaMvHgzA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/omesht/makemore-omesh/refs/heads/master/names.txt'\n",
        "words = requests.get(url).text.splitlines()\n",
        "#words = open('names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA23qPXZHgzB",
        "outputId": "79b49302-78cd-4d5a-fc52-f1aa553a530d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im75TwbbHgzC",
        "outputId": "6efc52dd-f272-4620-e888-edf535521ca6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYY3HIQ7HgzD",
        "outputId": "16141fb6-de74-4540-84ad-41fee38f7b31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "min(len(w) for w in words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3oyjVx7HgzD",
        "outputId": "f726cf79-bdd5-4fa1-ffcd-39959d61878c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "max(len(w) for w in words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INSI6Bs4HgzE"
      },
      "outputs": [],
      "source": [
        "b = {}\n",
        "for w in words:\n",
        "  chs = ['<S>'] + list(w) + ['<E>']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    bigram = (ch1, ch2)\n",
        "    b[bigram] = b.get(bigram, 0) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZlhHM1THgzE",
        "outputId": "821d6097-ec49-430a-a5f6-51398542861a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('n', '<E>'), 6763),\n",
              " (('a', '<E>'), 6640),\n",
              " (('a', 'n'), 5438),\n",
              " (('<S>', 'a'), 4410),\n",
              " (('e', '<E>'), 3983),\n",
              " (('a', 'r'), 3264),\n",
              " (('e', 'l'), 3248),\n",
              " (('r', 'i'), 3033),\n",
              " (('n', 'a'), 2977),\n",
              " (('<S>', 'k'), 2963),\n",
              " (('l', 'e'), 2921),\n",
              " (('e', 'n'), 2675),\n",
              " (('l', 'a'), 2623),\n",
              " (('m', 'a'), 2590),\n",
              " (('<S>', 'm'), 2538),\n",
              " (('a', 'l'), 2528),\n",
              " (('i', '<E>'), 2489),\n",
              " (('l', 'i'), 2480),\n",
              " (('i', 'a'), 2445),\n",
              " (('<S>', 'j'), 2422),\n",
              " (('o', 'n'), 2411),\n",
              " (('h', '<E>'), 2409),\n",
              " (('r', 'a'), 2356),\n",
              " (('a', 'h'), 2332),\n",
              " (('h', 'a'), 2244),\n",
              " (('y', 'a'), 2143),\n",
              " (('i', 'n'), 2126),\n",
              " (('<S>', 's'), 2055),\n",
              " (('a', 'y'), 2050),\n",
              " (('y', '<E>'), 2007),\n",
              " (('e', 'r'), 1958),\n",
              " (('n', 'n'), 1906),\n",
              " (('y', 'n'), 1826),\n",
              " (('k', 'a'), 1731),\n",
              " (('n', 'i'), 1725),\n",
              " (('r', 'e'), 1697),\n",
              " (('<S>', 'd'), 1690),\n",
              " (('i', 'e'), 1653),\n",
              " (('a', 'i'), 1650),\n",
              " (('<S>', 'r'), 1639),\n",
              " (('a', 'm'), 1634),\n",
              " (('l', 'y'), 1588),\n",
              " (('<S>', 'l'), 1572),\n",
              " (('<S>', 'c'), 1542),\n",
              " (('<S>', 'e'), 1531),\n",
              " (('j', 'a'), 1473),\n",
              " (('r', '<E>'), 1377),\n",
              " (('n', 'e'), 1359),\n",
              " (('l', 'l'), 1345),\n",
              " (('i', 'l'), 1345),\n",
              " (('i', 's'), 1316),\n",
              " (('l', '<E>'), 1314),\n",
              " (('<S>', 't'), 1308),\n",
              " (('<S>', 'b'), 1306),\n",
              " (('d', 'a'), 1303),\n",
              " (('s', 'h'), 1285),\n",
              " (('d', 'e'), 1283),\n",
              " (('e', 'e'), 1271),\n",
              " (('m', 'i'), 1256),\n",
              " (('s', 'a'), 1201),\n",
              " (('s', '<E>'), 1169),\n",
              " (('<S>', 'n'), 1146),\n",
              " (('a', 's'), 1118),\n",
              " (('y', 'l'), 1104),\n",
              " (('e', 'y'), 1070),\n",
              " (('o', 'r'), 1059),\n",
              " (('a', 'd'), 1042),\n",
              " (('t', 'a'), 1027),\n",
              " (('<S>', 'z'), 929),\n",
              " (('v', 'i'), 911),\n",
              " (('k', 'e'), 895),\n",
              " (('s', 'e'), 884),\n",
              " (('<S>', 'h'), 874),\n",
              " (('r', 'o'), 869),\n",
              " (('e', 's'), 861),\n",
              " (('z', 'a'), 860),\n",
              " (('o', '<E>'), 855),\n",
              " (('i', 'r'), 849),\n",
              " (('b', 'r'), 842),\n",
              " (('a', 'v'), 834),\n",
              " (('m', 'e'), 818),\n",
              " (('e', 'i'), 818),\n",
              " (('c', 'a'), 815),\n",
              " (('i', 'y'), 779),\n",
              " (('r', 'y'), 773),\n",
              " (('e', 'm'), 769),\n",
              " (('s', 't'), 765),\n",
              " (('h', 'i'), 729),\n",
              " (('t', 'e'), 716),\n",
              " (('n', 'd'), 704),\n",
              " (('l', 'o'), 692),\n",
              " (('a', 'e'), 692),\n",
              " (('a', 't'), 687),\n",
              " (('s', 'i'), 684),\n",
              " (('e', 'a'), 679),\n",
              " (('d', 'i'), 674),\n",
              " (('h', 'e'), 674),\n",
              " (('<S>', 'g'), 669),\n",
              " (('t', 'o'), 667),\n",
              " (('c', 'h'), 664),\n",
              " (('b', 'e'), 655),\n",
              " (('t', 'h'), 647),\n",
              " (('v', 'a'), 642),\n",
              " (('o', 'l'), 619),\n",
              " (('<S>', 'i'), 591),\n",
              " (('i', 'o'), 588),\n",
              " (('e', 't'), 580),\n",
              " (('v', 'e'), 568),\n",
              " (('a', 'k'), 568),\n",
              " (('a', 'a'), 556),\n",
              " (('c', 'e'), 551),\n",
              " (('a', 'b'), 541),\n",
              " (('i', 't'), 541),\n",
              " (('<S>', 'y'), 535),\n",
              " (('t', 'i'), 532),\n",
              " (('s', 'o'), 531),\n",
              " (('m', '<E>'), 516),\n",
              " (('d', '<E>'), 516),\n",
              " (('<S>', 'p'), 515),\n",
              " (('i', 'c'), 509),\n",
              " (('k', 'i'), 509),\n",
              " (('o', 's'), 504),\n",
              " (('n', 'o'), 496),\n",
              " (('t', '<E>'), 483),\n",
              " (('j', 'o'), 479),\n",
              " (('u', 's'), 474),\n",
              " (('a', 'c'), 470),\n",
              " (('n', 'y'), 465),\n",
              " (('e', 'v'), 463),\n",
              " (('s', 's'), 461),\n",
              " (('m', 'o'), 452),\n",
              " (('i', 'k'), 445),\n",
              " (('n', 't'), 443),\n",
              " (('i', 'd'), 440),\n",
              " (('j', 'e'), 440),\n",
              " (('a', 'z'), 435),\n",
              " (('i', 'g'), 428),\n",
              " (('i', 'm'), 427),\n",
              " (('r', 'r'), 425),\n",
              " (('d', 'r'), 424),\n",
              " (('<S>', 'f'), 417),\n",
              " (('u', 'r'), 414),\n",
              " (('r', 'l'), 413),\n",
              " (('y', 's'), 401),\n",
              " (('<S>', 'o'), 394),\n",
              " (('e', 'd'), 384),\n",
              " (('a', 'u'), 381),\n",
              " (('c', 'o'), 380),\n",
              " (('k', 'y'), 379),\n",
              " (('d', 'o'), 378),\n",
              " (('<S>', 'v'), 376),\n",
              " (('t', 't'), 374),\n",
              " (('z', 'e'), 373),\n",
              " (('z', 'i'), 364),\n",
              " (('k', '<E>'), 363),\n",
              " (('g', 'h'), 360),\n",
              " (('t', 'r'), 352),\n",
              " (('k', 'o'), 344),\n",
              " (('t', 'y'), 341),\n",
              " (('g', 'e'), 334),\n",
              " (('g', 'a'), 330),\n",
              " (('l', 'u'), 324),\n",
              " (('b', 'a'), 321),\n",
              " (('d', 'y'), 317),\n",
              " (('c', 'k'), 316),\n",
              " (('<S>', 'w'), 307),\n",
              " (('k', 'h'), 307),\n",
              " (('u', 'l'), 301),\n",
              " (('y', 'e'), 301),\n",
              " (('y', 'r'), 291),\n",
              " (('m', 'y'), 287),\n",
              " (('h', 'o'), 287),\n",
              " (('w', 'a'), 280),\n",
              " (('s', 'l'), 279),\n",
              " (('n', 's'), 278),\n",
              " (('i', 'z'), 277),\n",
              " (('u', 'n'), 275),\n",
              " (('o', 'u'), 275),\n",
              " (('n', 'g'), 273),\n",
              " (('y', 'd'), 272),\n",
              " (('c', 'i'), 271),\n",
              " (('y', 'o'), 271),\n",
              " (('i', 'v'), 269),\n",
              " (('e', 'o'), 269),\n",
              " (('o', 'm'), 261),\n",
              " (('r', 'u'), 252),\n",
              " (('f', 'a'), 242),\n",
              " (('b', 'i'), 217),\n",
              " (('s', 'y'), 215),\n",
              " (('n', 'c'), 213),\n",
              " (('h', 'y'), 213),\n",
              " (('p', 'a'), 209),\n",
              " (('r', 't'), 208),\n",
              " (('q', 'u'), 206),\n",
              " (('p', 'h'), 204),\n",
              " (('h', 'r'), 204),\n",
              " (('j', 'u'), 202),\n",
              " (('g', 'r'), 201),\n",
              " (('p', 'e'), 197),\n",
              " (('n', 'l'), 195),\n",
              " (('y', 'i'), 192),\n",
              " (('g', 'i'), 190),\n",
              " (('o', 'd'), 190),\n",
              " (('r', 's'), 190),\n",
              " (('r', 'd'), 187),\n",
              " (('h', 'l'), 185),\n",
              " (('s', 'u'), 185),\n",
              " (('a', 'x'), 182),\n",
              " (('e', 'z'), 181),\n",
              " (('e', 'k'), 178),\n",
              " (('o', 'v'), 176),\n",
              " (('a', 'j'), 175),\n",
              " (('o', 'h'), 171),\n",
              " (('u', 'e'), 169),\n",
              " (('m', 'm'), 168),\n",
              " (('a', 'g'), 168),\n",
              " (('h', 'u'), 166),\n",
              " (('x', '<E>'), 164),\n",
              " (('u', 'a'), 163),\n",
              " (('r', 'm'), 162),\n",
              " (('a', 'w'), 161),\n",
              " (('f', 'i'), 160),\n",
              " (('z', '<E>'), 160),\n",
              " (('u', '<E>'), 155),\n",
              " (('u', 'm'), 154),\n",
              " (('e', 'c'), 153),\n",
              " (('v', 'o'), 153),\n",
              " (('e', 'h'), 152),\n",
              " (('p', 'r'), 151),\n",
              " (('d', 'd'), 149),\n",
              " (('o', 'a'), 149),\n",
              " (('w', 'e'), 149),\n",
              " (('w', 'i'), 148),\n",
              " (('y', 'm'), 148),\n",
              " (('z', 'y'), 147),\n",
              " (('n', 'z'), 145),\n",
              " (('y', 'u'), 141),\n",
              " (('r', 'n'), 140),\n",
              " (('o', 'b'), 140),\n",
              " (('k', 'l'), 139),\n",
              " (('m', 'u'), 139),\n",
              " (('l', 'd'), 138),\n",
              " (('h', 'n'), 138),\n",
              " (('u', 'd'), 136),\n",
              " (('<S>', 'x'), 134),\n",
              " (('t', 'l'), 134),\n",
              " (('a', 'f'), 134),\n",
              " (('o', 'e'), 132),\n",
              " (('e', 'x'), 132),\n",
              " (('e', 'g'), 125),\n",
              " (('f', 'e'), 123),\n",
              " (('z', 'l'), 123),\n",
              " (('u', 'i'), 121),\n",
              " (('v', 'y'), 121),\n",
              " (('e', 'b'), 121),\n",
              " (('r', 'h'), 121),\n",
              " (('j', 'i'), 119),\n",
              " (('o', 't'), 118),\n",
              " (('d', 'h'), 118),\n",
              " (('h', 'm'), 117),\n",
              " (('c', 'l'), 116),\n",
              " (('o', 'o'), 115),\n",
              " (('y', 'c'), 115),\n",
              " (('o', 'w'), 114),\n",
              " (('o', 'c'), 114),\n",
              " (('f', 'r'), 114),\n",
              " (('b', '<E>'), 114),\n",
              " (('m', 'b'), 112),\n",
              " (('z', 'o'), 110),\n",
              " (('i', 'b'), 110),\n",
              " (('i', 'u'), 109),\n",
              " (('k', 'r'), 109),\n",
              " (('g', '<E>'), 108),\n",
              " (('y', 'v'), 106),\n",
              " (('t', 'z'), 105),\n",
              " (('b', 'o'), 105),\n",
              " (('c', 'y'), 104),\n",
              " (('y', 't'), 104),\n",
              " (('u', 'b'), 103),\n",
              " (('u', 'c'), 103),\n",
              " (('x', 'a'), 103),\n",
              " (('b', 'l'), 103),\n",
              " (('o', 'y'), 103),\n",
              " (('x', 'i'), 102),\n",
              " (('i', 'f'), 101),\n",
              " (('r', 'c'), 99),\n",
              " (('c', '<E>'), 97),\n",
              " (('m', 'r'), 97),\n",
              " (('n', 'u'), 96),\n",
              " (('o', 'p'), 95),\n",
              " (('i', 'h'), 95),\n",
              " (('k', 's'), 95),\n",
              " (('l', 's'), 94),\n",
              " (('u', 'k'), 93),\n",
              " (('<S>', 'q'), 92),\n",
              " (('d', 'u'), 92),\n",
              " (('s', 'm'), 90),\n",
              " (('r', 'k'), 90),\n",
              " (('i', 'x'), 89),\n",
              " (('v', '<E>'), 88),\n",
              " (('y', 'k'), 86),\n",
              " (('u', 'w'), 86),\n",
              " (('g', 'u'), 85),\n",
              " (('b', 'y'), 83),\n",
              " (('e', 'p'), 83),\n",
              " (('g', 'o'), 83),\n",
              " (('s', 'k'), 82),\n",
              " (('u', 't'), 82),\n",
              " (('a', 'p'), 82),\n",
              " (('e', 'f'), 82),\n",
              " (('i', 'i'), 82),\n",
              " (('r', 'v'), 80),\n",
              " (('f', '<E>'), 80),\n",
              " (('t', 'u'), 78),\n",
              " (('y', 'z'), 78),\n",
              " (('<S>', 'u'), 78),\n",
              " (('l', 't'), 77),\n",
              " (('r', 'g'), 76),\n",
              " (('c', 'r'), 76),\n",
              " (('i', 'j'), 76),\n",
              " (('w', 'y'), 73),\n",
              " (('z', 'u'), 73),\n",
              " (('l', 'v'), 72),\n",
              " (('h', 't'), 71),\n",
              " (('j', '<E>'), 71),\n",
              " (('x', 't'), 70),\n",
              " (('o', 'i'), 69),\n",
              " (('e', 'u'), 69),\n",
              " (('o', 'k'), 68),\n",
              " (('b', 'd'), 65),\n",
              " (('a', 'o'), 63),\n",
              " (('p', 'i'), 61),\n",
              " (('s', 'c'), 60),\n",
              " (('d', 'l'), 60),\n",
              " (('l', 'm'), 60),\n",
              " (('a', 'q'), 60),\n",
              " (('f', 'o'), 60),\n",
              " (('p', 'o'), 59),\n",
              " (('n', 'k'), 58),\n",
              " (('w', 'n'), 58),\n",
              " (('u', 'h'), 58),\n",
              " (('e', 'j'), 55),\n",
              " (('n', 'v'), 55),\n",
              " (('s', 'r'), 55),\n",
              " (('o', 'z'), 54),\n",
              " (('i', 'p'), 53),\n",
              " (('l', 'b'), 52),\n",
              " (('i', 'q'), 52),\n",
              " (('w', '<E>'), 51),\n",
              " (('m', 'c'), 51),\n",
              " (('s', 'p'), 51),\n",
              " (('e', 'w'), 50),\n",
              " (('k', 'u'), 50),\n",
              " (('v', 'r'), 48),\n",
              " (('u', 'g'), 47),\n",
              " (('o', 'x'), 45),\n",
              " (('u', 'z'), 45),\n",
              " (('z', 'z'), 45),\n",
              " (('j', 'h'), 45),\n",
              " (('b', 'u'), 45),\n",
              " (('o', 'g'), 44),\n",
              " (('n', 'r'), 44),\n",
              " (('f', 'f'), 44),\n",
              " (('n', 'j'), 44),\n",
              " (('z', 'h'), 43),\n",
              " (('c', 'c'), 42),\n",
              " (('r', 'b'), 41),\n",
              " (('x', 'o'), 41),\n",
              " (('b', 'h'), 41),\n",
              " (('p', 'p'), 39),\n",
              " (('x', 'l'), 39),\n",
              " (('h', 'v'), 39),\n",
              " (('b', 'b'), 38),\n",
              " (('m', 'p'), 38),\n",
              " (('x', 'x'), 38),\n",
              " (('u', 'v'), 37),\n",
              " (('x', 'e'), 36),\n",
              " (('w', 'o'), 36),\n",
              " (('c', 't'), 35),\n",
              " (('z', 'm'), 35),\n",
              " (('t', 's'), 35),\n",
              " (('m', 's'), 35),\n",
              " (('c', 'u'), 35),\n",
              " (('o', 'f'), 34),\n",
              " (('u', 'x'), 34),\n",
              " (('k', 'w'), 34),\n",
              " (('p', '<E>'), 33),\n",
              " (('g', 'l'), 32),\n",
              " (('z', 'r'), 32),\n",
              " (('d', 'n'), 31),\n",
              " (('g', 't'), 31),\n",
              " (('g', 'y'), 31),\n",
              " (('h', 's'), 31),\n",
              " (('x', 's'), 31),\n",
              " (('g', 's'), 30),\n",
              " (('x', 'y'), 30),\n",
              " (('y', 'g'), 30),\n",
              " (('d', 'm'), 30),\n",
              " (('d', 's'), 29),\n",
              " (('h', 'k'), 29),\n",
              " (('y', 'x'), 28),\n",
              " (('q', '<E>'), 28),\n",
              " (('g', 'n'), 27),\n",
              " (('y', 'b'), 27),\n",
              " (('g', 'w'), 26),\n",
              " (('n', 'h'), 26),\n",
              " (('k', 'n'), 26),\n",
              " (('g', 'g'), 25),\n",
              " (('d', 'g'), 25),\n",
              " (('l', 'c'), 25),\n",
              " (('r', 'j'), 25),\n",
              " (('w', 'u'), 25),\n",
              " (('l', 'k'), 24),\n",
              " (('m', 'd'), 24),\n",
              " (('s', 'w'), 24),\n",
              " (('s', 'n'), 24),\n",
              " (('h', 'd'), 24),\n",
              " (('w', 'h'), 23),\n",
              " (('y', 'j'), 23),\n",
              " (('y', 'y'), 23),\n",
              " (('r', 'z'), 23),\n",
              " (('d', 'w'), 23),\n",
              " (('w', 'r'), 22),\n",
              " (('t', 'n'), 22),\n",
              " (('l', 'f'), 22),\n",
              " (('y', 'h'), 22),\n",
              " (('r', 'w'), 21),\n",
              " (('s', 'b'), 21),\n",
              " (('m', 'n'), 20),\n",
              " (('f', 'l'), 20),\n",
              " (('w', 's'), 20),\n",
              " (('k', 'k'), 20),\n",
              " (('h', 'z'), 20),\n",
              " (('g', 'd'), 19),\n",
              " (('l', 'h'), 19),\n",
              " (('n', 'm'), 19),\n",
              " (('x', 'z'), 19),\n",
              " (('u', 'f'), 19),\n",
              " (('f', 't'), 18),\n",
              " (('l', 'r'), 18),\n",
              " (('p', 't'), 17),\n",
              " (('t', 'c'), 17),\n",
              " (('k', 't'), 17),\n",
              " (('d', 'v'), 17),\n",
              " (('u', 'p'), 16),\n",
              " (('p', 'l'), 16),\n",
              " (('l', 'w'), 16),\n",
              " (('p', 's'), 16),\n",
              " (('o', 'j'), 16),\n",
              " (('r', 'q'), 16),\n",
              " (('y', 'p'), 15),\n",
              " (('l', 'p'), 15),\n",
              " (('t', 'v'), 15),\n",
              " (('r', 'p'), 14),\n",
              " (('l', 'n'), 14),\n",
              " (('e', 'q'), 14),\n",
              " (('f', 'y'), 14),\n",
              " (('s', 'v'), 14),\n",
              " (('u', 'j'), 14),\n",
              " (('v', 'l'), 14),\n",
              " (('q', 'a'), 13),\n",
              " (('u', 'y'), 13),\n",
              " (('q', 'i'), 13),\n",
              " (('w', 'l'), 13),\n",
              " (('p', 'y'), 12),\n",
              " (('y', 'f'), 12),\n",
              " (('c', 'q'), 11),\n",
              " (('j', 'r'), 11),\n",
              " (('n', 'w'), 11),\n",
              " (('n', 'f'), 11),\n",
              " (('t', 'w'), 11),\n",
              " (('m', 'z'), 11),\n",
              " (('u', 'o'), 10),\n",
              " (('f', 'u'), 10),\n",
              " (('l', 'z'), 10),\n",
              " (('h', 'w'), 10),\n",
              " (('u', 'q'), 10),\n",
              " (('j', 'y'), 10),\n",
              " (('s', 'z'), 10),\n",
              " (('s', 'd'), 9),\n",
              " (('j', 'l'), 9),\n",
              " (('d', 'j'), 9),\n",
              " (('k', 'm'), 9),\n",
              " (('r', 'f'), 9),\n",
              " (('h', 'j'), 9),\n",
              " (('v', 'n'), 8),\n",
              " (('n', 'b'), 8),\n",
              " (('i', 'w'), 8),\n",
              " (('h', 'b'), 8),\n",
              " (('b', 's'), 8),\n",
              " (('w', 't'), 8),\n",
              " (('w', 'd'), 8),\n",
              " (('v', 'v'), 7),\n",
              " (('v', 'u'), 7),\n",
              " (('j', 's'), 7),\n",
              " (('m', 'j'), 7),\n",
              " (('f', 's'), 6),\n",
              " (('l', 'g'), 6),\n",
              " (('l', 'j'), 6),\n",
              " (('j', 'w'), 6),\n",
              " (('n', 'x'), 6),\n",
              " (('y', 'q'), 6),\n",
              " (('w', 'k'), 6),\n",
              " (('g', 'm'), 6),\n",
              " (('x', 'u'), 5),\n",
              " (('m', 'h'), 5),\n",
              " (('m', 'l'), 5),\n",
              " (('j', 'm'), 5),\n",
              " (('c', 's'), 5),\n",
              " (('j', 'v'), 5),\n",
              " (('n', 'p'), 5),\n",
              " (('d', 'f'), 5),\n",
              " (('x', 'd'), 5),\n",
              " (('z', 'b'), 4),\n",
              " (('f', 'n'), 4),\n",
              " (('x', 'c'), 4),\n",
              " (('m', 't'), 4),\n",
              " (('t', 'm'), 4),\n",
              " (('z', 'n'), 4),\n",
              " (('z', 't'), 4),\n",
              " (('p', 'u'), 4),\n",
              " (('c', 'z'), 4),\n",
              " (('b', 'n'), 4),\n",
              " (('z', 's'), 4),\n",
              " (('f', 'w'), 4),\n",
              " (('d', 't'), 4),\n",
              " (('j', 'd'), 4),\n",
              " (('j', 'c'), 4),\n",
              " (('y', 'w'), 4),\n",
              " (('v', 'k'), 3),\n",
              " (('x', 'w'), 3),\n",
              " (('t', 'j'), 3),\n",
              " (('c', 'j'), 3),\n",
              " (('q', 'w'), 3),\n",
              " (('g', 'b'), 3),\n",
              " (('o', 'q'), 3),\n",
              " (('r', 'x'), 3),\n",
              " (('d', 'c'), 3),\n",
              " (('g', 'j'), 3),\n",
              " (('x', 'f'), 3),\n",
              " (('z', 'w'), 3),\n",
              " (('d', 'k'), 3),\n",
              " (('u', 'u'), 3),\n",
              " (('m', 'v'), 3),\n",
              " (('c', 'x'), 3),\n",
              " (('l', 'q'), 3),\n",
              " (('p', 'b'), 2),\n",
              " (('t', 'g'), 2),\n",
              " (('q', 's'), 2),\n",
              " (('t', 'x'), 2),\n",
              " (('f', 'k'), 2),\n",
              " (('b', 't'), 2),\n",
              " (('j', 'n'), 2),\n",
              " (('k', 'c'), 2),\n",
              " (('z', 'k'), 2),\n",
              " (('s', 'j'), 2),\n",
              " (('s', 'f'), 2),\n",
              " (('z', 'j'), 2),\n",
              " (('n', 'q'), 2),\n",
              " (('f', 'z'), 2),\n",
              " (('h', 'g'), 2),\n",
              " (('w', 'w'), 2),\n",
              " (('k', 'j'), 2),\n",
              " (('j', 'k'), 2),\n",
              " (('w', 'm'), 2),\n",
              " (('z', 'c'), 2),\n",
              " (('z', 'v'), 2),\n",
              " (('w', 'f'), 2),\n",
              " (('q', 'm'), 2),\n",
              " (('k', 'z'), 2),\n",
              " (('j', 'j'), 2),\n",
              " (('z', 'p'), 2),\n",
              " (('j', 't'), 2),\n",
              " (('k', 'b'), 2),\n",
              " (('m', 'w'), 2),\n",
              " (('h', 'f'), 2),\n",
              " (('c', 'g'), 2),\n",
              " (('t', 'f'), 2),\n",
              " (('h', 'c'), 2),\n",
              " (('q', 'o'), 2),\n",
              " (('k', 'd'), 2),\n",
              " (('k', 'v'), 2),\n",
              " (('s', 'g'), 2),\n",
              " (('z', 'd'), 2),\n",
              " (('q', 'r'), 1),\n",
              " (('d', 'z'), 1),\n",
              " (('p', 'j'), 1),\n",
              " (('q', 'l'), 1),\n",
              " (('p', 'f'), 1),\n",
              " (('q', 'e'), 1),\n",
              " (('b', 'c'), 1),\n",
              " (('c', 'd'), 1),\n",
              " (('m', 'f'), 1),\n",
              " (('p', 'n'), 1),\n",
              " (('w', 'b'), 1),\n",
              " (('p', 'c'), 1),\n",
              " (('h', 'p'), 1),\n",
              " (('f', 'h'), 1),\n",
              " (('b', 'j'), 1),\n",
              " (('f', 'g'), 1),\n",
              " (('z', 'g'), 1),\n",
              " (('c', 'p'), 1),\n",
              " (('p', 'k'), 1),\n",
              " (('p', 'm'), 1),\n",
              " (('x', 'n'), 1),\n",
              " (('s', 'q'), 1),\n",
              " (('k', 'f'), 1),\n",
              " (('m', 'k'), 1),\n",
              " (('x', 'h'), 1),\n",
              " (('g', 'f'), 1),\n",
              " (('v', 'b'), 1),\n",
              " (('j', 'p'), 1),\n",
              " (('g', 'z'), 1),\n",
              " (('v', 'd'), 1),\n",
              " (('d', 'b'), 1),\n",
              " (('v', 'h'), 1),\n",
              " (('h', 'h'), 1),\n",
              " (('g', 'v'), 1),\n",
              " (('d', 'q'), 1),\n",
              " (('x', 'b'), 1),\n",
              " (('w', 'z'), 1),\n",
              " (('h', 'q'), 1),\n",
              " (('j', 'b'), 1),\n",
              " (('x', 'm'), 1),\n",
              " (('w', 'g'), 1),\n",
              " (('t', 'b'), 1),\n",
              " (('z', 'x'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sorted(b.items(), key = lambda kv: -kv[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-ptf2v3KHgzE"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AkXR0a84HgzF"
      },
      "outputs": [],
      "source": [
        "N = torch.zeros((27, 27, 27), dtype=torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iq1MP_0DHgzF"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itos"
      ],
      "metadata": {
        "id": "EE3m-vG8H0J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2RPHCMylHgzF"
      },
      "outputs": [],
      "source": [
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    N[ix1, ix2, ix3] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0sPVKjgHgzG",
        "outputId": "3a2bb6c0-6d3a-4db0-b7b7-e8fb2fa3a91a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10075, 10282, 10265, 10106, 10441, 10130, 10096, 10092, 10166, 10229,\n",
              "        10102, 10150, 10707, 10459, 10698, 10085, 10092, 10084, 10557, 10269,\n",
              "        10147, 10227, 10318, 10081, 10102, 10248, 10227], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "N[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N, cmap='Blues')\n",
        "for i in range(27):\n",
        "    for j in range(27):\n",
        "        chstr = itos[i] + itos[j]\n",
        "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "0LHlfrbBZuPH",
        "outputId": "10da0eb2-0545-431d-e214-46423409afee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Invalid shape (27, 27, 27) for image data",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-31-1879597069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3590\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3591\u001b[0m ) -> AxesImage:\n\u001b[0;32m-> 3592\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   3593\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3594\u001b[0m         \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             return func(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5943\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5945\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5946\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5947\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_image_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# If just (M, N, 1), assume scalar and apply colormap.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid shape {A.shape} for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;31m# If the input data has values outside the valid range (after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (27, 27, 27) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFw5m0RgHgzG",
        "outputId": "a164df91-bad1-4b6f-e3c8-a70652aeb6e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "p = N[0,0].float()\n",
        "p = p / p.sum()\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "nWh0KbFzHgzG",
        "outputId": "ee05a008-677d-4947-83a9-d18206eb6dd1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "invalid multinomial distribution (sum of probabilities <= 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-3580069904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2147483647\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (sum of probabilities <= 0)"
          ]
        }
      ],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "itos[ix]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9S0DusqHgzG",
        "outputId": "52e78728-4fe2-437b-9d70-30c8f2ccf7d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.6064, 0.3033, 0.0903])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "p = torch.rand(3, generator=g)\n",
        "p = p / p.sum()\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuSIWknsHgzG",
        "outputId": "d66f5e65-5be1-4107-9b76-3491cd74a0b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0,\n",
              "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0,\n",
              "        0, 1, 1, 1])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.multinomial(p, num_samples=100, replacement=True, generator=g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PllnLy2iHgzG",
        "outputId": "2838755b-95dc-4568-966e-d2f92c23352f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Oqr03hHHgzG",
        "outputId": "ffb48a85-a8ee-4ac1-acb5-9ba95bc108ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([27, 27])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "P.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqxOQ1qNHgzH",
        "outputId": "3de92521-7c96-4613-b54b-74dc35a9427c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([27, 1])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "P.sum(1, keepdim=True).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_ldW16wHgzH"
      },
      "outputs": [],
      "source": [
        "# 27, 27\n",
        "# 27,  1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXzwzbxiHgzH",
        "outputId": "e016f4ac-2fc6-49d8-f0f0-eb98568f3450"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([27])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "P.sum(1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLMZVMKtHgzH"
      },
      "outputs": [],
      "source": [
        "# 27, 27\n",
        "#  1, 27"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRPDPf54HgzH"
      },
      "outputs": [],
      "source": [
        "P = (N+1).float()\n",
        "P /= P.sum(1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FboBobwMHgzH",
        "outputId": "ce8b080a-184d-4bcb-f276-cbfbcfe1bb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mor.\n",
            "axx.\n",
            "minaymoryles.\n",
            "kondlaisah.\n",
            "anchshizarie.\n"
          ]
        }
      ],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_hLJj7PHgzH"
      },
      "outputs": [],
      "source": [
        "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
        "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
        "# equivalent to minimizing the negative log likelihood\n",
        "# equivalent to minimizing the average negative log likelihood\n",
        "\n",
        "# log(a*b*c) = log(a) + log(b) + log(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwYCPzugHgzH",
        "outputId": "687527ad-202c-4f6a-bec2-df0a0b0fd29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log_likelihood=tensor(-564996.8125, grad_fn=<AddBackward0>)\n",
            "nll=tensor(564996.8125, grad_fn=<NegBackward0>)\n",
            "2.476470470428467\n"
          ]
        }
      ],
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "#for w in [\"andrejq\"]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1, ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print(f'{log_likelihood=}')\n",
        "nll = -log_likelihood\n",
        "print(f'{nll=}')\n",
        "print(f'{nll/n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRJ37ToZHgzI",
        "outputId": "a004b2bc-344c-4d53-e89c-42160d35f109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ". e\n",
            "e m\n",
            "m m\n",
            "m a\n",
            "a .\n"
          ]
        }
      ],
      "source": [
        "# create the training set of bigrams (x,y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    print(ch1, ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uz4EaNgHgzI",
        "outputId": "4dbf40c8-02f1-49ea-dd46-97d247fa5a57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1e0MMYeHgzI",
        "outputId": "6de23243-ccf5-485a-cc9b-9ce64dd45b5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "execution_count": 451,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZb2TQr8HgzI",
        "outputId": "5df5c887-54b7-4279-d375-8dad4cc1ffff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 487,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "xenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qizbM6cZHgzI",
        "outputId": "dc407be0-dbd9-4653-f585-3de450ea6385"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "execution_count": 488,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xenc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyofAeVSHgzI",
        "outputId": "bc98a75c-43f2-4f81-cf26-3b87abaf316c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa0dab44fa0>"
            ]
          },
          "execution_count": 489,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(xenc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfHxaSeOHgzI",
        "outputId": "9860c59e-0524-48da-f9e0-fba77f684957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 490,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xenc.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-25bUlVcHgzJ",
        "outputId": "0f0cd606-56c7-48bf-e14a-a334ff7ff9ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.2003, -2.3711, -0.9466,  0.5369, -0.0949, -1.7872, -0.9038,  0.8194,\n",
              "          0.6926,  0.0114, -1.5301,  0.6077, -1.2056,  1.8605, -1.3012, -0.0301,\n",
              "         -2.1611, -0.0538, -0.0133, -0.3629,  0.5254, -0.0080,  1.1602,  1.9851,\n",
              "          0.4976,  0.7351, -0.6373],\n",
              "        [-0.4422,  0.5024,  1.3514, -0.4085, -0.7854, -1.2568, -0.4558,  0.1466,\n",
              "         -0.4460,  1.2748, -0.6367,  0.6403, -0.5617, -0.3060,  1.6771, -1.4814,\n",
              "         -2.7395,  0.3876,  0.3970,  1.5577, -0.1995, -0.1397, -1.3045,  0.4294,\n",
              "          1.2557,  0.8007,  0.5450],\n",
              "        [-0.2680, -0.2640,  0.4591,  0.0338,  0.7478,  1.2757, -0.9842,  0.1799,\n",
              "          0.0824, -0.5646, -0.3657, -0.8358, -1.7654,  0.5008, -1.7455, -0.8160,\n",
              "         -2.2721,  0.9713, -1.0734,  0.3115, -0.2506,  0.0757,  0.9332,  1.6536,\n",
              "          1.2306,  0.1231, -0.2530],\n",
              "        [-0.2680, -0.2640,  0.4591,  0.0338,  0.7478,  1.2757, -0.9842,  0.1799,\n",
              "          0.0824, -0.5646, -0.3657, -0.8358, -1.7654,  0.5008, -1.7455, -0.8160,\n",
              "         -2.2721,  0.9713, -1.0734,  0.3115, -0.2506,  0.0757,  0.9332,  1.6536,\n",
              "          1.2306,  0.1231, -0.2530],\n",
              "        [ 0.1949, -1.1315,  0.9479, -0.6382, -0.4422, -0.6489,  0.6576, -1.9004,\n",
              "          2.0254,  1.2617, -1.7238,  1.2971, -0.6925, -0.3873,  0.7874, -0.8088,\n",
              "          0.5746, -0.5263, -0.5928,  0.1419,  1.0683, -0.1760, -0.3507, -0.5358,\n",
              "          0.1470,  1.5682, -1.0393]])"
            ]
          },
          "execution_count": 493,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W = torch.randn((27, 1))\n",
        "xenc @ W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pruhylJXHgzJ",
        "outputId": "fd0302b1-ba6f-424b-81f8-17c4f567c879"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0205, 0.0023, 0.0097, 0.0428, 0.0228, 0.0042, 0.0101, 0.0568, 0.0500,\n",
              "         0.0253, 0.0054, 0.0460, 0.0075, 0.1609, 0.0068, 0.0243, 0.0029, 0.0237,\n",
              "         0.0247, 0.0174, 0.0423, 0.0248, 0.0799, 0.1822, 0.0412, 0.0522, 0.0132],\n",
              "        [0.0154, 0.0397, 0.0928, 0.0160, 0.0110, 0.0068, 0.0152, 0.0278, 0.0154,\n",
              "         0.0860, 0.0127, 0.0456, 0.0137, 0.0177, 0.1286, 0.0055, 0.0016, 0.0354,\n",
              "         0.0357, 0.1141, 0.0197, 0.0209, 0.0065, 0.0369, 0.0844, 0.0535, 0.0414],\n",
              "        [0.0212, 0.0213, 0.0439, 0.0287, 0.0586, 0.0994, 0.0104, 0.0332, 0.0301,\n",
              "         0.0158, 0.0192, 0.0120, 0.0047, 0.0458, 0.0048, 0.0123, 0.0029, 0.0733,\n",
              "         0.0095, 0.0379, 0.0216, 0.0299, 0.0705, 0.1450, 0.0950, 0.0314, 0.0215],\n",
              "        [0.0212, 0.0213, 0.0439, 0.0287, 0.0586, 0.0994, 0.0104, 0.0332, 0.0301,\n",
              "         0.0158, 0.0192, 0.0120, 0.0047, 0.0458, 0.0048, 0.0123, 0.0029, 0.0733,\n",
              "         0.0095, 0.0379, 0.0216, 0.0299, 0.0705, 0.1450, 0.0950, 0.0314, 0.0215],\n",
              "        [0.0289, 0.0077, 0.0613, 0.0126, 0.0153, 0.0124, 0.0459, 0.0036, 0.1801,\n",
              "         0.0839, 0.0042, 0.0869, 0.0119, 0.0161, 0.0522, 0.0106, 0.0422, 0.0140,\n",
              "         0.0131, 0.0274, 0.0692, 0.0199, 0.0167, 0.0139, 0.0275, 0.1140, 0.0084]])"
            ]
          },
          "execution_count": 506,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits = xenc @ W # log-counts\n",
        "counts = logits.exp() # equivalent N\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzTns3kdHgzJ",
        "outputId": "6d08a478-48cd-4883-c59b-80ecc1c60344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0205, 0.0023, 0.0097, 0.0428, 0.0228, 0.0042, 0.0101, 0.0568, 0.0500,\n",
              "        0.0253, 0.0054, 0.0460, 0.0075, 0.1609, 0.0068, 0.0243, 0.0029, 0.0237,\n",
              "        0.0247, 0.0174, 0.0423, 0.0248, 0.0799, 0.1822, 0.0412, 0.0522, 0.0132])"
            ]
          },
          "execution_count": 509,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Q22IacHgzJ",
        "outputId": "f4fa5539-127a-4da0-8546-80afa5a4bf7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([27])"
            ]
          },
          "execution_count": 510,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yVwHjdnHgzJ",
        "outputId": "ce19f826-8c8b-4971-c8f2-a280287d7d52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "execution_count": 507,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs[0].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo3GSpGOHgzO"
      },
      "outputs": [],
      "source": [
        "# (5, 27) @ (27, 27) -> (5, 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovBtVsahHgzO"
      },
      "outputs": [],
      "source": [
        "# SUMMARY ------------------------------>>>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-tj7W_ZHgzO",
        "outputId": "9936ac11-038d-4934-9996-7dd620d69038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "execution_count": 528,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y8bYQU8HgzO",
        "outputId": "fae43981-56da-44af-c6de-b6d16a589795"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "execution_count": 529,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2YMFz9qHgzO"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4ZOEGG9HgzO"
      },
      "outputs": [],
      "source": [
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# btw: the last 2 lines here are together called a 'softmax'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYgEUNnQHgzO",
        "outputId": "e07df22e-c6b6-4b17-f78b-1349de204b50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "execution_count": 559,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhaXRlKTHgzO",
        "outputId": "4e7ee9b6-477a-4a7f-d68e-91565c1a207b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------\n",
            "bigram example 1: .e (indexes 0,5)\n",
            "input to the neural net: 0\n",
            "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
            "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
            "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
            "label (actual next character): 5\n",
            "probability assigned by the net to the the correct character: 0.012286253273487091\n",
            "log likelihood: -4.3992743492126465\n",
            "negative log likelihood: 4.3992743492126465\n",
            "--------\n",
            "bigram example 2: em (indexes 5,13)\n",
            "input to the neural net: 5\n",
            "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
            "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
            "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the the correct character: 0.018050702288746834\n",
            "log likelihood: -4.014570713043213\n",
            "negative log likelihood: 4.014570713043213\n",
            "--------\n",
            "bigram example 3: mm (indexes 13,13)\n",
            "input to the neural net: 13\n",
            "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
            "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
            "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the the correct character: 0.026691533625125885\n",
            "log likelihood: -3.623408794403076\n",
            "negative log likelihood: 3.623408794403076\n",
            "--------\n",
            "bigram example 4: ma (indexes 13,1)\n",
            "input to the neural net: 13\n",
            "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
            "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
            "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
            "label (actual next character): 1\n",
            "probability assigned by the net to the the correct character: 0.07367684692144394\n",
            "log likelihood: -2.6080667972564697\n",
            "negative log likelihood: 2.6080667972564697\n",
            "--------\n",
            "bigram example 5: a. (indexes 1,0)\n",
            "input to the neural net: 1\n",
            "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
            "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
            "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
            "label (actual next character): 0\n",
            "probability assigned by the net to the the correct character: 0.0149775305762887\n",
            "log likelihood: -4.201204299926758\n",
            "negative log likelihood: 4.201204299926758\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('--------')\n",
        "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probabilities from the neural net:', probs[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i, y]\n",
        "  print('probability assigned by the net to the the correct character:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood:', logp.item())\n",
        "  nll = -logp\n",
        "  print('negative log likelihood:', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcCv7uRzHgzO"
      },
      "outputs": [],
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay --------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YNuL7F_HgzP",
        "outputId": "27817aec-b121-4f44-8902-9301ff5f625d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "execution_count": 565,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqfnqhJ1HgzP",
        "outputId": "1ac60d2f-bcbd-4704-f031-676386c297d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0])"
            ]
          },
          "execution_count": 566,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3Bh2AAjHgzP"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qje_HNEpHgzP"
      },
      "outputs": [],
      "source": [
        "# forward pass\n",
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "loss = -probs[torch.arange(5), ys].log().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf1JuXFoHgzP",
        "outputId": "584b4ffd-4204-4575-c7e6-3a21d3afdebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.6891887187957764\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRJ5pO-eHgzP"
      },
      "outputs": [],
      "source": [
        "# backward pass\n",
        "W.grad = None # set to zero the gradient\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOTb9UacHgzP"
      },
      "outputs": [],
      "source": [
        "W.data += -0.1 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrMHPlvhHgzP"
      },
      "outputs": [],
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iOwTXeqHgzP",
        "outputId": "3e54f497-c5e9-412f-edcd-2d99949d8142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ],
      "source": [
        "# create the dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# initialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGeAKlNpHgzP",
        "outputId": "f12e2462-e882-413d-b65a-75c3ab4dca13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.481828451156616\n"
          ]
        }
      ],
      "source": [
        "# gradient descent\n",
        "for k in range(1):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-bj1jhnHgzP",
        "outputId": "a224bcb8-7f49-40cc-ee4b-2fd1afdcca40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mor.\n",
            "axx.\n",
            "minaymoryles.\n",
            "kondlaisah.\n",
            "anchthizarie.\n"
          ]
        }
      ],
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "\n",
        "    # ----------\n",
        "    # BEFORE:\n",
        "    #p = P[ix]\n",
        "    # ----------\n",
        "    # NOW:\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    # ----------\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twafdXfwHgzQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}